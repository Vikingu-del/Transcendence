services:

  # swagger:
  #   container_name: swagger
  #   build:
  #     context: ./Swagger
  #     dockerfile: Dockerfile
  #   environment:
  #     URLS_PRIMARY_NAME: "UserService" # Default API to display in Swagger UI
  #     URLS: '[{ "url": "/doc/ApiGateway.yaml", "name": "ApiGateway" }, 
  #        { "url": "/doc/UserService.yaml", "name": "UserService" },
  #        { "url": "/doc/Security.yaml", "name": "Security" },
  #        { "url": "/doc/Database.yaml", "name": "Database" },
  #        { "url": "/doc/FrontEnd.yaml", "name": "FrontEnd" }]'
  #   volumes:
  #     - ./docs/openapi:/usr/share/nginx/html/doc # Mount local OpenAPI specs
  #   ports:
  #     - "8080:8080"  # Swagger UI available at localhost:8080
  #   restart: always
  #   networks:
  #     backtier:

  vault:
    container_name: vault
    build:
      context: ./Security/Vault
      dockerfile: Dockerfile
    cap_add:
      - IPC_LOCK
    ports:
      - "8200:8200"
    networks:
      - backtier
    environment:
      - VAULT_ADDR=http://vault:8200
    volumes:
      - vault_data:/vault/file
      - vault_token:/vault/token
      - approle_user:/vault/approle/user
      - approle_user_db:/vault/approle/user_db  
      - approle_gateway:/vault/approle/gateway
      - approle_chat:/vault/approle/chat
      - approle_chat_db:/vault/approle/chat_db
      - approle_auth:/vault/approle/auth
      - approle_auth_db:/vault/approle/auth_db
    healthcheck:
      test: ["CMD", "vault", "status", "-address=http://localhost:8200"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 5s

  vault_secrets:
    container_name: vault_secrets
    build:
      context: ./Security/VaultSecrets
      dockerfile: Dockerfile
    env_file:
      - ./Security/VaultSecrets/secrets/.env
    networks:
      - backtier
    depends_on:
      vault:
        condition: service_healthy
    restart: on-failure
    volumes:
      - vault_token:/vault/token:ro
      - approle_user:/vault/approle/user
      - approle_user_db:/vault/approle/user_db
      - approle_gateway:/vault/approle/gateway
      - approle_chat:/vault/approle/chat
      - approle_chat_db:/vault/approle/chat_db
      - approle_auth:/vault/approle/auth
      - approle_auth_db:/vault/approle/auth_db

  user:
    container_name: user
    build:
      context: ./Backend/userService
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./Backend/userService:/app
      - approle_user:/vault/approle/user:ro
    environment:
      - DJANGO_SETTINGS_MODULE=userService.settings
      - API_PREFIX=/api/user
      # - DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,10.12.12.5,user_service,user,user_db,gateway
    depends_on:
      vault:
        condition: service_started
      vault_secrets:
        condition: service_completed_successfully
      user_db:
        condition: service_healthy
    networks:
      - backtier

  user_db:
    container_name: user_db
    build:
      context: ./Database/user_db
      dockerfile: Dockerfile
    restart: always
    depends_on:
      vault:
        condition: service_healthy
      vault_secrets:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/usr/local/bin/healthcheck.sh"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports: 
      - "5432:5432"
    volumes:
      - approle_user_db:/vault/approle/user_db:ro
      - user_db_data:/var/lib/postgresql/data
    networks:
      - backtier

  chat:
    container_name: chat
    build:
      context: ./Backend/chatService
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    volumes:
      - ./Backend/chatService:/app
      - approle_chat:/vault/approle/chat:ro
    environment:
      - DJANGO_SETTINGS_MODULE=chatService.settings
      - API_PREFIX=/api/chat
    depends_on:
      vault:
        condition: service_started
      vault_secrets:
        condition: service_completed_successfully
      chat_db:
        condition: service_healthy
    networks:
      - backtier
    
  chat_db:
    container_name: chat_db
    build:
      context: ./Database/chat_db
      dockerfile: Dockerfile
    restart: always
    depends_on:
      vault:
        condition: service_healthy
      vault_secrets:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/usr/local/bin/healthcheck.sh"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5433:5432"
    volumes:
      - approle_chat_db:/vault/approle/chat_db:ro
      - chat_db_data:/var/lib/postgresql/data
    networks:
      - backtier

  auth:
    container_name: auth
    build:
      context: ./Backend/authService
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./Backend/authService:/app
      - approle_auth:/vault/approle/auth:ro
    environment:
      - DJANGO_SETTINGS_MODULE=authService.settings
      - USER_SERVICE_URL=http://user:8000  # For service communication
      - INTERNAL_API_KEY=your-secure-key-here #AddddDDDED IVAN
      - DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,auth,gateway,0.0.0.0,* #AddddDDDED IVAN
      - DEBUG=1 #AddddDDDED IVAN
      - PORT=8001 #AddddDDDED IVAN
    depends_on:
      vault:
        condition: service_started
      vault_secrets:
        condition: service_completed_successfully
      auth_db:
        condition: service_healthy
    networks:
      - backtier

  auth_db:
    container_name: auth_db
    build:
      context: ./Database/auth_db
      dockerfile: Dockerfile
    restart: always
    depends_on:
      vault:
        condition: service_healthy
      vault_secrets:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/usr/local/bin/healthcheck.sh"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5434:5432"
    volumes:
      - approle_auth_db:/vault/approle/auth_db:ro
      - auth_db_data:/var/lib/postgresql/data
    networks:
      - backtier
    

  gateway:
    container_name: gateway
    build:
      context: ./ApiGateway
      dockerfile: Dockerfile
    ports:
      - 80:80
      - 443:443
    depends_on:
      - vault
      - vault_secrets
      - user
      - frontend
      - chat
      - auth
    volumes:
      - approle_gateway:/vault/approle/gateway:ro
      - ./ApiGateway/config/nginx.conf.template:/etc/nginx/templates/nginx.conf.template:ro
      - ./ApiGateway/config/modsecurity:/etc/nginx/templates/modsecurity:ro
      - ./.cert/:/etc/nginx/ssl/:ro
    environment:
      - NGINX_HOST=${NGINX_HOST:-10.12.12.5}
      - NGINX_PORT=${NGINX_PORT:-443}
    networks:
      - backtier
      - frontier

  frontend:
    container_name: frontend
    build:
      context: ./FrontEnd
      dockerfile: Dockerfile
    ports:
      - "5173:5173"  # Vite's default dev server port
    volumes:
      - ./FrontEnd:/app
      - /app/node_modules # Preserve node_modules from container
    environment:
      - NODE_ENV=development
      - VITE_HOST=0.0.0.0
      - VITE_API_URL=${NGINX_HOST:-10.12.12.5}
    command: npm run dev -- --host
    networks:
      - frontier

  elasticsearch:
    image: elasticsearch:${ELK_VERSION}
    build:
      context: elk/elasticsearch/
      args:
        ELK_VERSION: ${ELK_VERSION}
    restart: unless-stopped
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTIC_CLUSTER_NAME: ${ELASTIC_CLUSTER_NAME}
      ELASTIC_NODE_NAME: ${ELASTIC_NODE_NAME}
      ELASTIC_INIT_MASTER_NODE: ${ELASTIC_INIT_MASTER_NODE}
      ELASTIC_DISCOVERY_SEEDS: ${ELASTIC_DISCOVERY_SEEDS}
      ES_JAVA_OPTS: "-Xmx${ELASTICSEARCH_HEAP} -Xms${ELASTICSEARCH_HEAP} -Des.enforce.bootstrap.checks=true -Dlog4j2.formatMsgNoLookups=true"
      bootstrap.memory_lock: "true"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./elk/elasticsearch/config/log4j2.properties:/usr/share/elasticsearch/config/log4j2.properties
    secrets:
      - source: elasticsearch.keystore
        target: /usr/share/elasticsearch/config/elasticsearch.keystore
      - source: elasticsearch.service_tokens
        target: /usr/share/elasticsearch/config/service_tokens
      - source: elastic.ca
        target: /usr/share/elasticsearch/config/certs/ca.crt
      - source: elasticsearch.certificate
        target: /usr/share/elasticsearch/config/certs/elasticsearch.crt
      - source: elasticsearch.key
        target: /usr/share/elasticsearch/config/certs/elasticsearch.key
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 200000
        hard: 200000
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -sf --insecure https://$ELASTIC_USERNAME:$ELASTIC_PASSWORD@localhost:9200/_cat/health | grep -ioE 'green|yellow' || echo 'not green/yellow cluster status'"]

  logstash:
    image: logstash:${ELK_VERSION}
    build:
      context: elk/logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    restart: unless-stopped
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./elk/secrets/certs/ca/ca.crt:/usr/share/logstash/config/certs/ca.crt:ro
    secrets:
      - source: elastic.ca
        target: /certs/ca.crt
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
      LS_JAVA_OPTS: "-Xmx${LOGSTASH_HEAP} -Xms${LOGSTASH_HEAP} -Dlog4j2.formatMsgNoLookups=true"
    ports:
      - "5044:5044"
      - "9600:9600"
    healthcheck:
      test: ["CMD", "curl", "-s" ,"-XGET", "http://127.0.0.1:9600"]

  kibana:
    image: kibana:${ELK_VERSION}
    build:
      context: elk/kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    restart: unless-stopped
    volumes:
      - ./elk/kibana/config/:/usr/share/kibana/config:ro
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
    env_file:
      - ./elk/secrets/.env.kibana.token
    secrets:
      - source: elastic.ca
        target: /certs/ca.crt
      - source: kibana.certificate
        target: /certs/kibana.crt
      - source: kibana.key
        target: /certs/kibana.key
    ports:
      - "5601:5601"

  # Docker Logs Shipper ------------------------------
  filebeat:
    image: docker.elastic.co/beats/filebeat:${ELK_VERSION}
    restart: always
    # -e flag to log to stderr and disable syslog/file output
    command: -e --strict.perms=false
    user: root
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      KIBANA_HOST_PORT: ${KIBANA_HOST}:${KIBANA_PORT}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro 

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    expose:
      - "9090:9090"
    networks:
      - monitoring
    restart: always
    depends_on:
      - node-exporter

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    expose:
      - "9100"
    networks:
      - monitoring
    restart: always
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: always
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - ./monitoring/dashboard.yaml:/etc/grafana/provisioning/dashboards/dashboard.yaml
      - ./monitoring/dashboard.json:/var/lib/grafana/dashboards/dashboard.json
    networks:
      - monitoring
    depends_on:
      - prometheus

secrets:
  elasticsearch.keystore:
    file: ./elk/secrets/keystore/elasticsearch.keystore
  elasticsearch.service_tokens:
    file: ./elk/secrets/service_tokens
  elastic.ca:
    file: ./elk/secrets/certs/ca/ca.crt
  elasticsearch.certificate:
    file: ./elk/secrets/certs/elasticsearch/elasticsearch.crt
  elasticsearch.key:
    file: ./elk/secrets/certs/elasticsearch/elasticsearch.key
  kibana.certificate:
    file: ./elk/secrets/certs/kibana/kibana.crt
  kibana.key:
    file: ./elk/secrets/certs/kibana/kibana.key

volumes:
  vault_data:
  vault_token:
  approle_user:
  approle_user_db:
  approle_gateway:
  user_db_data:
  chat_db_data:
  auth_db_data:
  approle_chat:
  approle_chat_db:
  approle_auth:
  approle_auth_db:
  elasticsearch-data:
  grafana-data:
  prometheus-data:

networks:
  user_network:
    driver: bridge
  backtier:
    driver: bridge
    name: backtier
  frontier:
    driver: bridge
    name: frontier
  monitoring:
    driver: bridge
    name: monitoring
